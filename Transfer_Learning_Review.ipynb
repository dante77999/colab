{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZVYd2fmx4O+JCGGiQIdtu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fac13a5a03e14f97af708b0d5f173f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46cb199b8adc491190389849aad2ad76",
              "IPY_MODEL_83d78c6262b04147b1892bfa713b363f",
              "IPY_MODEL_3fe4961d54c8418fb2b0e893716ef982"
            ],
            "layout": "IPY_MODEL_74540e986c2a489983e58c90de66f315"
          }
        },
        "46cb199b8adc491190389849aad2ad76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60373fe74e984247b0cac6650f216984",
            "placeholder": "​",
            "style": "IPY_MODEL_137083dfdf8f4393a94e8022cd8e0c9f",
            "value": " 30%"
          }
        },
        "83d78c6262b04147b1892bfa713b363f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f0b96d56daf4c7895d69b7fdaf63db0",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74fa6c782ccb4aba8262a1e27a328780",
            "value": 6
          }
        },
        "3fe4961d54c8418fb2b0e893716ef982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23bc4dec545148978a4a760e5f0bf5f1",
            "placeholder": "​",
            "style": "IPY_MODEL_d26966ecc5dc4226be9d0bf663c6e1ec",
            "value": " 6/20 [00:30&lt;01:00,  4.33s/it]"
          }
        },
        "74540e986c2a489983e58c90de66f315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60373fe74e984247b0cac6650f216984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137083dfdf8f4393a94e8022cd8e0c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f0b96d56daf4c7895d69b7fdaf63db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74fa6c782ccb4aba8262a1e27a328780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23bc4dec545148978a4a760e5f0bf5f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d26966ecc5dc4226be9d0bf663c6e1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dante77999/colab/blob/main/Transfer_Learning_Review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "2CW7qJQpAfPB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs0EpetXs7g7",
        "outputId": "4b1d6718-96e4-4d66-eed0-bfa3e4e5f1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\")\n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / \"pizza_steak_sushi.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"data/pizza_steak_sushi/train\"\n",
        "test_dir = \"data/pizza_steak_sushi/test\""
      ],
      "metadata": {
        "id": "gZOAvtcN6UaK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "vit = torchvision.models.vit_b_16(weights=torchvision.models.ViT_B_16_Weights.DEFAULT)"
      ],
      "metadata": {
        "id": "C5H58zZc7WAU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in vit.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "vit.heads = torch.nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    torch.nn.Linear(in_features=768,out_features=3)\n",
        ")\n",
        "\n",
        "vit.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DLJX0CbW_Gkn",
        "outputId": "83846db8-0e84-429c-a1ea-b28a11feecef"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "  (encoder): Encoder(\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): Sequential(\n",
              "      (encoder_layer_0): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_1): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_2): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_3): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_4): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_5): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_6): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_7): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_8): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_9): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_10): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (encoder_layer_11): EncoderBlock(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (self_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (heads): Sequential(\n",
              "    (0): Dropout(p=0.3, inplace=False)\n",
              "    (1): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    !pip install torchinfo"
      ],
      "metadata": {
        "id": "F4wEpwHl2zIU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model=vit,\n",
        "        input_size=(32,3,224,224),col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzQKUG9F_o1q",
        "outputId": "b498c61c-c9a3-4cf8-a6fd-d1b4e34a1d61"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "VisionTransformer (VisionTransformer)                        [32, 3, 224, 224]    [32, 3]              768                  Partial\n",
              "├─Conv2d (conv_proj)                                         [32, 3, 224, 224]    [32, 768, 14, 14]    (590,592)            False\n",
              "├─Encoder (encoder)                                          [32, 197, 768]       [32, 197, 768]       151,296              False\n",
              "│    └─Dropout (dropout)                                     [32, 197, 768]       [32, 197, 768]       --                   --\n",
              "│    └─Sequential (layers)                                   [32, 197, 768]       [32, 197, 768]       --                   False\n",
              "│    │    └─EncoderBlock (encoder_layer_0)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_1)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_2)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_3)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_4)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_5)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_6)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_7)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_8)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_9)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_10)                  [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    │    └─EncoderBlock (encoder_layer_11)                  [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
              "│    └─LayerNorm (ln)                                        [32, 197, 768]       [32, 197, 768]       (1,536)              False\n",
              "├─Sequential (heads)                                         [32, 768]            [32, 3]              --                   True\n",
              "│    └─Dropout (0)                                           [32, 768]            [32, 768]            --                   --\n",
              "│    └─Linear (1)                                            [32, 768]            [32, 3]              2,307                True\n",
              "============================================================================================================================================\n",
              "Total params: 85,800,963\n",
              "Trainable params: 2,307\n",
              "Non-trainable params: 85,798,656\n",
              "Total mult-adds (Units.GIGABYTES): 5.52\n",
              "============================================================================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 3330.74\n",
              "Params size (MB): 229.20\n",
              "Estimated Total Size (MB): 3579.21\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare data\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "# vit_transform = torchvision.models.ViT_B_16_Weights.IMAGENET1K_V1.transforms()\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # 先放大一點\n",
        "    transforms.RandomCrop(224, padding=4),  # 隨機裁剪\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # 50% 機率水平翻轉\n",
        "    transforms.RandomRotation(degrees=15),  # 隨機旋轉 ±15 度\n",
        "    transforms.ColorJitter(\n",
        "        brightness=0.2,  # 亮度變化 ±20%\n",
        "        contrast=0.2,    # 對比度變化 ±20%\n",
        "        saturation=0.2,  # 飽和度變化 ±20%\n",
        "        hue=0.1         # 色調變化 ±10%\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])  # ImageNet 標準化\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 直接縮放到目標大小\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "batch_size=16\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir,transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir,transform=test_transform)\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True,\n",
        "                              pin_memory=True,\n",
        "                              num_workers=1,\n",
        "                              )\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                             batch_size=32,\n",
        "                             shuffle=False,\n",
        "                             pin_memory=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "class_names = train_dataset.classes"
      ],
      "metadata": {
        "id": "bOOVjhktBJzj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.samples[123]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3qhVQvun6dS",
        "outputId": "d287b650-2ba3-4819-e00f-b7903e786642"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('data/pizza_steak_sushi/train/steak/2648423.jpg', 1)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_dataloader)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "i14eI2FsnwWr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Early stopping version\n"
      ],
      "metadata": {
        "id": "4-BtsArl8nMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train process\n",
        "from tqdm.auto import tqdm\n",
        "import copy\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optim = torch.optim.AdamW(params=vit.parameters(),\n",
        "                        lr=0.001,\n",
        "                        weight_decay=1e-4,\n",
        "                        betas=(0.9, 0.999))\n",
        "\n",
        "\n",
        "schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optim,\n",
        "    mode=\"max\",\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    verbose=True,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "epochs = 20\n",
        "n = 0\n",
        "\n",
        "#early stopping 參數\n",
        "patience = 5\n",
        "best_test_acc = 0.0\n",
        "patience_counter = 0\n",
        "best_model_state = None\n",
        "\n",
        "results={\n",
        "        \"train_loss\":[],\n",
        "        \"train_acc\":[],\n",
        "        \"test_loss\":[],\n",
        "        \"test_acc\":[]\n",
        "    }\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    n+=1\n",
        "    current_lr = optim.param_groups[0][\"lr\"] # 獲取當前學習率\n",
        "\n",
        "    vit.train()\n",
        "\n",
        "    train_loss,train_acc = 0, 0\n",
        "    test_loss,test_acc = 0, 0\n",
        "\n",
        "    #0. let dataloader to device\n",
        "    for batch,(X,y) in enumerate(train_dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        #1. load the data to model\n",
        "\n",
        "        y_train_pred_logit =  vit(X)\n",
        "\n",
        "        #2. calculate the loss\n",
        "\n",
        "        loss = loss_fn(y_train_pred_logit,y)\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "        #3.optim zero grad\n",
        "\n",
        "        optim.zero_grad()\n",
        "\n",
        "        #4.backwards\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        #5.optim step\n",
        "\n",
        "        optim.step()\n",
        "\n",
        "        #turn logit into prob\n",
        "        y_train_prob = torch.argmax((torch.softmax(y_train_pred_logit,dim=1)),dim=1)\n",
        "        train_acc += (y_train_prob==y).sum().item() / len(y)\n",
        "\n",
        "    train_loss = train_loss / len(train_dataloader)\n",
        "    train_acc = train_acc / len(train_dataloader)\n",
        "\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "\n",
        "    vit.eval()\n",
        "    with torch.inference_mode():\n",
        "        for batch,(X,y) in enumerate(test_dataloader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            y_test_logit = vit(X)\n",
        "            t_loss = loss_fn(y_test_logit,y)\n",
        "            test_loss+=t_loss.item()\n",
        "\n",
        "            #turn into pred\n",
        "\n",
        "            y_test_pred = torch.argmax(torch.softmax(y_test_logit,dim=1),dim=1)\n",
        "            test_acc += (y_test_pred==y).sum().item() / len(y)\n",
        "\n",
        "        test_loss = test_loss / len(test_dataloader)\n",
        "        test_acc = test_acc / len(test_dataloader)\n",
        "\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    print(f\"Epoch {n}: train_loss={train_loss:.4f} | train_acc={train_acc:.4f} | test_loss={test_loss:.4f} | test_acc={test_acc:.4f} | lr={current_lr:.6f}\")\n",
        "\n",
        "    if test_acc > best_test_acc:\n",
        "        patience_counter = 0\n",
        "        best_test_acc = test_acc\n",
        "        best_model_state = copy.deepcopy(vit.state_dict())\n",
        "        print(f\"✓ 新的最佳測試準確率: {best_test_acc:.4f}\")\n",
        "    else:\n",
        "        patience_counter+=1\n",
        "        print(f\"⚠️  測試準確率未提升 ({patience_counter}/{patience})\")\n",
        "\n",
        "    if train_acc > 0.95 and (train_acc - test_acc) > 0.2:\n",
        "        print(f\"⚠️  警告：可能過擬合！訓練準確率 {train_acc:.4f} 遠高於測試準確率 {test_acc:.4f}\")\n",
        "\n",
        "    schedular.step(test_acc)\n",
        "\n",
        "    if patience_counter > patience:\n",
        "        print(f\"\\n🛑 Early Stopping! 測試準確率已經 {patience} 個 epochs 沒有提升\")\n",
        "\n",
        "        break\n",
        "if best_model_state is not None:\n",
        "    vit.load_state_dict(best_model_state)\n",
        "    print(f\"\\n✅ 已載入最佳模型 (測試準確率: {best_test_acc:.4f})\")\n",
        "print(\"已經訓練完成!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "fac13a5a03e14f97af708b0d5f173f4a",
            "46cb199b8adc491190389849aad2ad76",
            "83d78c6262b04147b1892bfa713b363f",
            "3fe4961d54c8418fb2b0e893716ef982",
            "74540e986c2a489983e58c90de66f315",
            "60373fe74e984247b0cac6650f216984",
            "137083dfdf8f4393a94e8022cd8e0c9f",
            "4f0b96d56daf4c7895d69b7fdaf63db0",
            "74fa6c782ccb4aba8262a1e27a328780",
            "23bc4dec545148978a4a760e5f0bf5f1",
            "d26966ecc5dc4226be9d0bf663c6e1ec"
          ]
        },
        "outputId": "d95c4a0a-23bb-4343-a8d8-2264054b3770",
        "id": "Km6ONbdO8pi-"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fac13a5a03e14f97af708b0d5f173f4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss=0.1465 | train_acc=0.9750 | test_loss=0.1870 | test_acc=0.9384 | lr=0.001000\n",
            "✓ 新的最佳測試準確率: 0.9384\n",
            "Epoch 2: train_loss=0.1349 | train_acc=0.9750 | test_loss=0.1764 | test_acc=0.9384 | lr=0.001000\n",
            "⚠️  測試準確率未提升 (1/5)\n",
            "Epoch 3: train_loss=0.1341 | train_acc=0.9708 | test_loss=0.2193 | test_acc=0.9384 | lr=0.001000\n",
            "⚠️  測試準確率未提升 (2/5)\n",
            "Epoch 4: train_loss=0.1060 | train_acc=0.9667 | test_loss=0.2204 | test_acc=0.9384 | lr=0.001000\n",
            "⚠️  測試準確率未提升 (3/5)\n",
            "Epoch 5: train_loss=0.0711 | train_acc=0.9917 | test_loss=0.2055 | test_acc=0.9384 | lr=0.000500\n",
            "⚠️  測試準確率未提升 (4/5)\n",
            "Epoch 6: train_loss=0.0624 | train_acc=0.9958 | test_loss=0.1990 | test_acc=0.9384 | lr=0.000500\n",
            "⚠️  測試準確率未提升 (5/5)\n",
            "Epoch 7: train_loss=0.0762 | train_acc=0.9792 | test_loss=0.1982 | test_acc=0.9384 | lr=0.000500\n",
            "⚠️  測試準確率未提升 (6/5)\n",
            "\n",
            "🛑 Early Stopping! 測試準確率已經 5 個 epochs 沒有提升\n",
            "\n",
            "✅ 已載入最佳模型 (測試準確率: 0.9384)\n",
            "已經訓練完成!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8SF_fQY8-aQ7"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}